{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436631fd",
   "metadata": {},
   "source": [
    "# Parking Tickets Analysis - Ann Arbor\n",
    "\n",
    "This mini project analyzes parking ticket data from the city of Ann Arbor using Python and pandas. The data is obtained from FOIA requests and consists of multiple Excel files. Our analysis will include:\n",
    "\n",
    "1. Loading and combining the ticket data\n",
    "2. Generating descriptive statistics for ticket descriptions\n",
    "3. Identifying the most common car make for tickets issued to NY plates\n",
    "4. Analyzing the distribution of different types of Michigan license plates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947bbf71",
   "metadata": {},
   "source": [
    "## 1. Load and Combine Ticket Data\n",
    "\n",
    "The `load_ticket_data()` function reads and combines data from multiple Excel files into a single pandas DataFrame. It handles different sheets within files and standardizes the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06027424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet2 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet3 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2015.xls\n",
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet2 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet3 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2016.xls\n",
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet2 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet3 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2017.xls\n",
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet2 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet3 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2018.xls\n",
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet2 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet3 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation2019.xls\n",
      "Processing sheet: Sheet1 from file: C:/Users/akama/Downloads/AnnArbor-TicketViolation-jan2020.xls\n",
      "DataFrame Shape: (811398, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket #</th>\n",
       "      <th>Badge</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>IssueTime</th>\n",
       "      <th>Plate</th>\n",
       "      <th>State</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meter</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2110008524</td>\n",
       "      <td>826</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1719</td>\n",
       "      <td>DCM1327</td>\n",
       "      <td>MI</td>\n",
       "      <td>SATU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>FARMER'S MARKET</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2110008525</td>\n",
       "      <td>826</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1725</td>\n",
       "      <td>BAX385</td>\n",
       "      <td>IA</td>\n",
       "      <td>CHEV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>FARMER'S MARKET</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2100005834</td>\n",
       "      <td>821</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1344</td>\n",
       "      <td>2LEH1</td>\n",
       "      <td>MI</td>\n",
       "      <td>FORD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A04</td>\n",
       "      <td>NO PRKNG ANYTME</td>\n",
       "      <td>600 BLK OF WILLIAM E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2090006959</td>\n",
       "      <td>827</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1608</td>\n",
       "      <td>A380673</td>\n",
       "      <td>OH</td>\n",
       "      <td>FORD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01</td>\n",
       "      <td>EXPIRED METER</td>\n",
       "      <td>200 BLK OF WASHINGTO</td>\n",
       "      <td>2029B</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2100005829</td>\n",
       "      <td>821</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>1326</td>\n",
       "      <td>ABD7951</td>\n",
       "      <td>AZ</td>\n",
       "      <td>HOND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A08</td>\n",
       "      <td>LOADING ZONE</td>\n",
       "      <td>1000 BLK OF UNIVERSI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticket # Badge           Issue Date IssueTime    Plate State  Make Model  \\\n",
       "0  2110008524   826  2015-01-02 00:00:00      1719  DCM1327    MI  SATU   NaN   \n",
       "1  2110008525   826  2015-01-02 00:00:00      1725   BAX385    IA  CHEV   NaN   \n",
       "2  2100005834   821  2015-01-02 00:00:00      1344    2LEH1    MI  FORD   NaN   \n",
       "3  2090006959   827  2015-01-02 00:00:00      1608  A380673    OH  FORD   NaN   \n",
       "4  2100005829   821  2015-01-02 00:00:00      1326  ABD7951    AZ  HOND   NaN   \n",
       "\n",
       "  Violation      Description              Location  Meter Fine Penalty  \n",
       "0       A01    EXPIRED METER       FARMER'S MARKET     17   10       0  \n",
       "1       A01    EXPIRED METER       FARMER'S MARKET     35   10       0  \n",
       "2       A04  NO PRKNG ANYTME  600 BLK OF WILLIAM E    NaN   25       0  \n",
       "3       A01    EXPIRED METER  200 BLK OF WASHINGTO  2029B   20       0  \n",
       "4       A08     LOADING ZONE  1000 BLK OF UNIVERSI    NaN   35       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_ticket_data():\n",
    "    def process_file(file):\n",
    "        data = pd.read_excel(file, sheet_name=None, header=None)\n",
    "        frames = []\n",
    "        \n",
    "        for sheet_name, df in data.items():\n",
    "            print(f\"Processing sheet: {sheet_name} from file: {file}\")  # Debug print\n",
    "            \n",
    "            # Remove header rows and reset columns\n",
    "            if not df.empty:\n",
    "                df = df.iloc[4:]  # Adjusting for header rows\n",
    "                df.columns = ['Ticket #', 'Badge', 'Issue Date', 'IssueTime', 'Plate', 'State', \n",
    "                              'Make', 'Model', 'Violation', 'Description', 'Location', 'Meter', \n",
    "                              'Fine', 'Penalty']\n",
    "                \n",
    "                # Remove footer row in the third sheet if present\n",
    "                if sheet_name == 'Sheet3':\n",
    "                    df = df[:-1]\n",
    "                    \n",
    "                frames.append(df)\n",
    "\n",
    "        # Combine frames if not empty\n",
    "        if frames:\n",
    "            df_combined = pd.concat(frames, ignore_index=True)\n",
    "            return df_combined\n",
    "\n",
    "        return pd.DataFrame()  # Return empty df if no valid frames\n",
    "\n",
    "    files = [\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation2015.xls',\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation2016.xls',\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation2017.xls',\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation2018.xls',\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation2019.xls',\n",
    "        'C:/Users/akama/Downloads/AnnArbor-TicketViolation-jan2020.xls'\n",
    "    ]\n",
    "\n",
    "    all_df = []\n",
    "    for file in files:\n",
    "        df = process_file(file)\n",
    "        if not df.empty:\n",
    "            all_df.append(df)\n",
    "        else:\n",
    "            print(f\"No data found in file: {file}\")  # Debug print\n",
    "\n",
    "    if all_df:\n",
    "        return pd.concat(all_df, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"No data found in any files.\")\n",
    "\n",
    "# Load the data\n",
    "df = load_ticket_data()\n",
    "print(f\"DataFrame Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2baf2a",
   "metadata": {},
   "source": [
    "## 2. Generate Descriptive Statistics for Ticket Descriptions\n",
    "\n",
    "The `generate_descriptors(df)` function generates a DataFrame of unique ticket descriptions and their frequencies for different times of the day: morning (3 AM - 11:59 AM), afternoon (12 PM - 5:59 PM), and evening (6 PM - 2:59 AM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd57344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPIRED METER</th>\n",
       "      <th>NO PRKNG ANYTME</th>\n",
       "      <th>LOADING ZONE</th>\n",
       "      <th>IMPROPER PARK</th>\n",
       "      <th>NO PERMIT CITY</th>\n",
       "      <th>PARKED ON WALK</th>\n",
       "      <th>15' FIRE HYDRAN</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>LEFT TO CURB</th>\n",
       "      <th>HANDICAP</th>\n",
       "      <th>...</th>\n",
       "      <th>NO PARK STADIUM DAYS</th>\n",
       "      <th>ODD/EVEN PARK</th>\n",
       "      <th>OVER LEGAL TIME LIMIT</th>\n",
       "      <th>PKD IN INTERSECTION</th>\n",
       "      <th>IMPROPER (SIGNED)</th>\n",
       "      <th>W/I 30' TRAF CONTROL</th>\n",
       "      <th>NO PKG HERE TO CORNER</th>\n",
       "      <th>ACROSS MARKED SPACES</th>\n",
       "      <th>UPON BRIDGE</th>\n",
       "      <th>BLOCKING TRAFFIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Morning</th>\n",
       "      <td>186962</td>\n",
       "      <td>7866</td>\n",
       "      <td>1468</td>\n",
       "      <td>1763</td>\n",
       "      <td>889</td>\n",
       "      <td>732</td>\n",
       "      <td>1152</td>\n",
       "      <td>24965</td>\n",
       "      <td>613</td>\n",
       "      <td>2604</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afternoon</th>\n",
       "      <td>267256</td>\n",
       "      <td>16277</td>\n",
       "      <td>4093</td>\n",
       "      <td>2224</td>\n",
       "      <td>1683</td>\n",
       "      <td>1252</td>\n",
       "      <td>2182</td>\n",
       "      <td>31440</td>\n",
       "      <td>1031</td>\n",
       "      <td>4306</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>9520</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evening</th>\n",
       "      <td>18</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>11</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EXPIRED METER  NO PRKNG ANYTME  LOADING ZONE  IMPROPER PARK  \\\n",
       "Morning           186962             7866          1468           1763   \n",
       "Afternoon         267256            16277          4093           2224   \n",
       "Evening               18              147             1              9   \n",
       "\n",
       "           NO PERMIT CITY  PARKED ON WALK  15' FIRE HYDRAN  OTHER  \\\n",
       "Morning               889             732             1152  24965   \n",
       "Afternoon            1683            1252             2182  31440   \n",
       "Evening                 0               4               10    105   \n",
       "\n",
       "           LEFT TO CURB  HANDICAP  ...  NO PARK STADIUM DAYS  ODD/EVEN PARK  \\\n",
       "Morning             613      2604  ...                   168              6   \n",
       "Afternoon          1031      4306  ...                    19              0   \n",
       "Evening              11       125  ...                     0              8   \n",
       "\n",
       "           OVER LEGAL TIME LIMIT  PKD IN INTERSECTION  IMPROPER (SIGNED)  \\\n",
       "Morning                      660                    0                  3   \n",
       "Afternoon                   9520                    2                  0   \n",
       "Evening                        0                    0                  0   \n",
       "\n",
       "           W/I 30' TRAF CONTROL  NO PKG HERE TO CORNER  ACROSS MARKED SPACES  \\\n",
       "Morning                       0                      1                     0   \n",
       "Afternoon                     5                      2                     1   \n",
       "Evening                       0                      0                     0   \n",
       "\n",
       "           UPON BRIDGE  BLOCKING TRAFFIC  \n",
       "Morning              0                 0  \n",
       "Afternoon            1                 1  \n",
       "Evening              0                 0  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_descriptors(df):\n",
    "    df['IssueTime'] = pd.to_numeric(df['IssueTime'], errors='coerce')\n",
    "    df = df.dropna(subset=['IssueTime'])\n",
    "    df['IssueTime'] = df['IssueTime'].astype(int)\n",
    "    \n",
    "    def get_period_count(df, start, end):\n",
    "        return {desc: len(df[(df['Description'] == desc) & (df['IssueTime'] >= start) & (df['IssueTime'] < end)])\n",
    "                for desc in df['Description'].dropna().unique()}\n",
    "    \n",
    "    morning_counts = get_period_count(df, 300, 1200)\n",
    "    afternoon_counts = get_period_count(df, 1200, 1800)\n",
    "    evening_counts = get_period_count(df, 1800, 2400) | get_period_count(df, 0, 300)\n",
    "    \n",
    "    return pd.DataFrame([morning_counts, afternoon_counts, evening_counts], \n",
    "                        index=[\"Morning\", \"Afternoon\", \"Evening\"])\n",
    "\n",
    "# Generate descriptors\n",
    "df_descriptors = generate_descriptors(df)\n",
    "print(df_descriptors.shape)\n",
    "df_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea770f",
   "metadata": {},
   "source": [
    "## 3. Identify the Most Common Car Make for NY Plates\n",
    "\n",
    "The `common_car_make()` function identifies the most common make of car that received tickets from the state of NY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d761909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common car make for NY plates is: JEEP\n"
     ]
    }
   ],
   "source": [
    "def common_car_make(df):\n",
    "    ny_tickets = df[df['State'] == 'NY']\n",
    "    most_common_make = ny_tickets['Make'].value_counts().idxmax()\n",
    "    return most_common_make\n",
    "\n",
    "# Identify the most common car make for NY plates\n",
    "most_common_make_ny = common_car_make(df)\n",
    "print(f\"The most common car make for NY plates is: {most_common_make_ny}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7fc76",
   "metadata": {},
   "source": [
    "## 4. Analyze Michigan Plates\n",
    "\n",
    "The `fine_per_plates()` function analyzes the distribution of different types of Michigan license plates that received tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76236bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABC1234': 467758, 'ABC123': 42564, '123ABC': 83, 'vanity': 171266}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def fine_per_plates(df):\n",
    "    mi_tickets = df[df['State'] == 'MI']\n",
    "    plates = mi_tickets['Plate'].dropna()\n",
    "    \n",
    "    pattern_abc1234 = re.compile(r'^[A-Z]{3}[0-9]{4}$')\n",
    "    pattern_abc123 = re.compile(r'^[A-Z]{3}[0-9]{3}$')\n",
    "    pattern_123abc = re.compile(r'^[0-9]{3}[A-Z]{3}$')\n",
    "    \n",
    "    plate_counts = {\n",
    "        \"ABC1234\": plates.str.contains(pattern_abc1234).sum(),\n",
    "        \"ABC123\": plates.str.contains(pattern_abc123).sum(),\n",
    "        \"123ABC\": plates.str.contains(pattern_123abc).sum()\n",
    "    }\n",
    "    plate_counts[\"vanity\"] = len(plates) - sum(plate_counts.values())\n",
    "    return plate_counts\n",
    "\n",
    "# Analyze Michigan plates\n",
    "mi_plate_distribution = fine_per_plates(df)\n",
    "print(mi_plate_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc514d5a",
   "metadata": {},
   "source": [
    "This brief project showcases my ability to manipulate and analyze large datasets using Python and pandas. The analyzed parking ticket data from Ann Arbor provides valuable insights into ticket trends and vehicle information. For further details, please check out my GitHub portfolio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
